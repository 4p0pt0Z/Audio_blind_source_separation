{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.signal import stft\n",
    "import librosa\n",
    "import numpy as np\n",
    "import h5py\n",
    "import collections\n",
    "import json\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"length_segments_s\": 3.3,\n",
    "          \n",
    "          \"audioset_data_folder\": '/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/',\n",
    "          \"output_folder\": \"/home/vincent/Audio_blind_source_separation/Datadir/audioset_segments\",\n",
    "    \n",
    "          \"sampling_rate\": 16000,\n",
    "          \n",
    "          \"STFT_frame_width_ms\": 64,\n",
    "          \"STFT_frame_shift_ms\": 32,\n",
    "          \"STFT_window_function\": \"hamming\",\n",
    "          \"detrend\": False,\n",
    "          \"boundary\": None,\n",
    "          \"padded\": False,\n",
    "          \n",
    "          \"n_Mel_filters\": 64,\n",
    "          \"Mel_min_freq\": 0,\n",
    "          \"Mel_max_freq\": 8000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STFT_frame_n_samples = int(config[\"sampling_rate\"] / (1000.0 / config[\"STFT_frame_width_ms\"]))\n",
    "STFT_frame_n_samples_shift = int(config[\"sampling_rate\"] / (1000.0 / config[\"STFT_frame_shift_ms\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of STFT frames in a segment with the input parameters: 101.125\n",
      "Rounding the length of the segments to 3.328 seconds, in order to have exactly 102 stft frames in each segment.\n",
      "There are 53248 audio samples in a segment.\n"
     ]
    }
   ],
   "source": [
    "n_stft_frames_in_segments = (config[\"length_segments_s\"] * config[\"sampling_rate\"] - STFT_frame_n_samples) / STFT_frame_n_samples_shift\n",
    "round_segments_length_s = np.round(config[\"length_segments_s\"] * config[\"sampling_rate\"] / STFT_frame_n_samples) \\\n",
    "                          * STFT_frame_n_samples / config[\"sampling_rate\"]\n",
    "segment_n_samples = int(round_segments_length_s * config[\"sampling_rate\"])\n",
    "new_n_stft_frames_in_segments = int((round_segments_length_s * config[\"sampling_rate\"] - STFT_frame_n_samples) / STFT_frame_n_samples_shift)\n",
    "print(\"Number of STFT frames in a segment with the input parameters: {}\".format(n_stft_frames_in_segments))\n",
    "print(\"Rounding the length of the segments to {} seconds\"\n",
    "      \", in order to have exactly {} stft frames in each segment.\".format(round_segments_length_s, new_n_stft_frames_in_segments))\n",
    "print(\"There are {} audio samples in a segment.\".format(segment_n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs_filenames = [os.path.join(dp, f) \n",
    "                     for dp, dn, fn in os.walk(os.path.expanduser(config[\"audioset_data_folder\"]))\n",
    "                     for f in fn\n",
    "                     if f.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_filenames = [os.path.splitext(wav_filename)[0] + '.txt' for wav_filename in all_wavs_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [directory for directory in os.listdir(config[\"audioset_data_folder\"])\n",
    "                     if os.path.isdir(os.path.join(config[\"audioset_data_folder\"], directory))] + ['Human Speech']\n",
    "config[\"classes\"] = classes\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_duration_in_segments(segment_start, segment_end, label_start_times, label_end_times):\n",
    "    \n",
    "    smaller_start_times = label_start_times[label_start_times <= segment_end]\n",
    "    greater_end_times = label_end_times[label_end_times >= segment_start]\n",
    "    if smaller_start_times.size == 0 or greater_end_times.size == 0:\n",
    "        return 0.0\n",
    "    in_seg_start_times = smaller_start_times[smaller_start_times >= segment_start]\n",
    "    in_seg_end_times = greater_end_times[greater_end_times <= segment_end]\n",
    "    if in_seg_end_times.size == 0:\n",
    "        in_seg_end_times = np.array([segment_end])\n",
    "    if in_seg_start_times.size == 0:\n",
    "        in_seg_start_times = np.array([segment_start])\n",
    "    \n",
    "    duration = 0.0\n",
    "    if in_seg_end_times[0] <= in_seg_start_times[0]:\n",
    "        duration += in_seg_end_times[0] - segment_start\n",
    "        in_seg_end_times = in_seg_end_times[1:]\n",
    "    if in_seg_end_times.size == 0 or in_seg_start_times[-1] >= in_seg_end_times[-1]:\n",
    "        duration += segment_end - in_seg_start_times[-1]\n",
    "        in_seg_start_times = in_seg_start_times[:-1]\n",
    "    duration += np.sum(in_seg_end_times - in_seg_start_times)\n",
    "    \n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label_file(filename, classes_list):\n",
    "    # read label file content\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [x.strip() for x in lines]\n",
    "    # Parse the time stamps per classes if any\n",
    "    timestamps = []\n",
    "    for a_class in classes_list:\n",
    "        # find idx of line with the class name\n",
    "        class_line_idx = [idx for idx, line in enumerate(lines)\n",
    "                          if line.find(a_class) > - 1\n",
    "                          and line.find('.eaf') == -1\n",
    "                          and line.find('AM') == -1\n",
    "                          and line.find('PM') == -1]\n",
    "        for line_idx_idx, line_idx in enumerate(class_line_idx):\n",
    "            # time stamps should be the line after the class name\n",
    "            segments_lines_idx = line_idx + 1\n",
    "\n",
    "            if segments_lines_idx < len(lines):\n",
    "                if line_idx_idx == 0:\n",
    "                    timestamps.append(np.array(list(\n",
    "                        map(float, filter(None,\n",
    "                                          lines[segments_lines_idx].replace('TC', '')\n",
    "                                          .replace('-', '\\t')\n",
    "                                          .replace('00:00:', '').split('\\t'))))))\n",
    "                else:\n",
    "                    additional_line_timestamps = np.array(list(\n",
    "                        map(float, filter(None,\n",
    "                                          lines[segments_lines_idx].replace('TC', '')\n",
    "                                          .replace('-', '\\t')\n",
    "                                          .replace('00:00:', '').split('\\t')))))\n",
    "                    timestamps[-1] = np.array(timestamps[-1].tolist() + additional_line_timestamps.tolist())\n",
    "            else:\n",
    "                timestamps.append(np.array([]))  # Sometimes the class name is in the label file but there are no timestamps\n",
    "        # class name is not present in the label file\n",
    "        if not class_line_idx:\n",
    "            timestamps.append(np.array([]))  # Sometines there is no class name and no timestamps\n",
    "\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config[\"output_folder\"]):\n",
    "    os.makedirs(config[\"output_folder\"])\n",
    "else:\n",
    "    if os.listdir(config[\"output_folder\"]):  # if folder is not empty\n",
    "        raise ValueError('Output folder already exist !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: ' 0.390                0.610 '\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Fire Alarm/xFqA0foiO7g_30000_40000.wav\n",
      "[Errno 2] No such file or directory: '/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Car Honking/Aqow6daDNYc_10000_20000.txt'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Car Honking/Aqow6daDNYc_10000_20000.wav\n",
      "[Errno 2] No such file or directory: '/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Car Honking/5BtgtrX7OuQ_70000_80000(1).txt'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Car Honking/5BtgtrX7OuQ_70000_80000(1).wav\n",
      "could not convert string to float: ' 3.760  8.162 '\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Glass Breaking/xfzunkprFeI_280000_290000.wav\n",
      "could not convert string to float: ' 8.576 8.716 '\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Smoke Alarm/XzKP2q6WPMU_30000_40000.wav\n",
      "could not convert string to float: ' 2.710  4.480 '\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Smoke Alarm/YCoWHIEAlOs_110000_120000.wav\n",
      "could not convert string to float: 'Human Speech'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Baby Cry/agOkrt8z688_30000_40000.wav\n",
      "could not convert string to float: 'Human Speech'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Baby Cry/AhXP21DcB2A_30000_40000.wav\n",
      "could not convert string to float: 'Human Speech'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Baby Cry/aeMVX-nsGMQ_30000_40000.wav\n",
      "could not convert string to float: 'Human Speech'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Baby Cry/AENoR7Jp8oo_30000_40000.wav\n",
      "could not convert string to float: 'Human Speech'\n",
      "/home/vincent/Audio_blind_source_separation/Datadir/cloud_factorized_audioset/Baby Cry/aeiXr2U079g_30000_40000.wav\n"
     ]
    }
   ],
   "source": [
    "labels = collections.deque()\n",
    "durations = collections.deque()\n",
    "mel_spectrograms = collections.deque()\n",
    "stft_magnitudes = collections.deque()\n",
    "stft_phases = collections.deque()\n",
    "segment_names = collections.deque()\n",
    "\n",
    "mel_filterbank = librosa.filters.mel(config[\"sampling_rate\"],\n",
    "                                     n_fft=STFT_frame_n_samples,\n",
    "                                     n_mels=config[\"n_Mel_filters\"],\n",
    "                                     fmin=config[\"Mel_min_freq\"],\n",
    "                                     fmax=config[\"Mel_max_freq\"])\n",
    "\n",
    "for idx, (audio_file, label_file) in enumerate(zip(all_wavs_filenames, all_labels_filenames)):\n",
    "    try:\n",
    "        audio, _ = librosa.core.load(audio_file, sr=config[\"sampling_rate\"], mono=True)\n",
    "        labels_segment = parse_label_file(label_file, classes)\n",
    "        if len(labels_segment) != len(classes):\n",
    "            raise ValueError('Length of labels_segment is ' + str(len(labels_segment)) + ' while there are only ' + str(len(classes)) + ' classes.')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(audio_file)\n",
    "        continue\n",
    "        \n",
    "    n_seg_in_audio = audio.shape[0] // segment_n_samples\n",
    "    audio = audio[:n_seg_in_audio*segment_n_samples]\n",
    "    segments = np.split(audio, n_seg_in_audio)\n",
    "    \n",
    "    for seg_idx, segment in enumerate(segments):\n",
    "        try:\n",
    "            durations.append(np.array([label_duration_in_segments(seg_idx*round_segments_length_s,\n",
    "                                                                  (seg_idx+1)*round_segments_length_s,\n",
    "                                                                  class_label_segments[::2], class_label_segments[1::2])\n",
    "                                       for class_label_segments in labels_segment]))\n",
    "        except:\n",
    "            print(labels_segment)\n",
    "        # The segment get a label for a class if at least 1 frame in the segment has the label\n",
    "        seg_labels = (np.array(durations[-1]) >= config[\"STFT_frame_width_ms\"] / 1000.0)\n",
    "        labels.append(seg_labels)\n",
    "        \n",
    "        _, _, seg_stft = stft(segment,\n",
    "                              window=config[\"STFT_window_function\"],\n",
    "                              nperseg=STFT_frame_n_samples,\n",
    "                              noverlap=STFT_frame_n_samples - STFT_frame_n_samples_shift,\n",
    "                              detrend=config[\"detrend\"],\n",
    "                              boundary=config[\"boundary\"],\n",
    "                              padded=config[\"padded\"])\n",
    "        \n",
    "        stft_magnitudes.append(np.abs(seg_stft))\n",
    "        stft_phases.append(seg_stft / (stft_magnitudes[-1] + 1e-15))\n",
    "        \n",
    "        mel_spectrograms.append(mel_filterbank @ stft_magnitudes[-1])\n",
    "        \n",
    "        name = os.path.join(config[\"output_folder\"],\n",
    "                            os.path.splitext(os.path.basename(audio_file))[0]\n",
    "                            + '_seg{}'.format(seg_idx) + '.wav')\n",
    "        segment_names.append(os.path.basename(name))\n",
    "        librosa.output.write_wav(name, segment, sr=config[\"sampling_rate\"], norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_magnitudes = np.array(stft_magnitudes).astype(np.float32)\n",
    "stft_phases = np.array(stft_phases)\n",
    "mel_spectrograms = np.array(mel_spectrograms).astype(np.float32)\n",
    "labels = np.array(labels).astype(np.float32)\n",
    "segment_names = np.array(segment_names)\n",
    "durations = np.array(durations).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(config[\"output_folder\"], 'all_data.hdf5'), 'w') as hdf5_file:\n",
    "    hdf5_file.create_dataset('stft_magnitudes', data=stft_magnitudes)\n",
    "    hdf5_file.create_dataset('stft_phases', data=stft_phases)\n",
    "    hdf5_file.create_dataset('mel_spectrograms', data=mel_spectrograms)\n",
    "    hdf5_file.create_dataset('labels', data=labels)\n",
    "    hdf5_file.create_dataset('filenames', data=[filename.encode(\"ascii\", \"ignore\") for filename in segment_names])\n",
    "    hdf5_file.create_dataset('durations', data=durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config[\"output_folder\"], 'config.json'), 'w') as config_file:\n",
    "    json.dump(config, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, dev, test split: 0.8, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sss = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, dev_test_index = next(tr_sss.split(np.zeros(stft_magnitudes.shape[0]), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_sss = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_index, test_index = next(dev_test_sss.split(np.zeros(stft_magnitudes[dev_test_index].shape[0]), labels[dev_test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(config[\"output_folder\"], 'train_data.hdf5'), 'w') as hdf5_file:\n",
    "    hdf5_file.create_dataset('stft_magnitudes', data=stft_magnitudes[train_index])\n",
    "    hdf5_file.create_dataset('stft_phases', data=stft_phases[train_index])\n",
    "    hdf5_file.create_dataset('mel_spectrograms', data=mel_spectrograms[train_index])\n",
    "    hdf5_file.create_dataset('labels', data=labels[train_index])\n",
    "    hdf5_file.create_dataset('filenames', data=[filename.encode(\"ascii\", \"ignore\") for filename in segment_names[train_index]])\n",
    "    hdf5_file.create_dataset('durations', data=durations[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(config[\"output_folder\"], 'dev_data.hdf5'), 'w') as hdf5_file:\n",
    "    hdf5_file.create_dataset('stft_magnitudes', data=stft_magnitudes[dev_test_index][dev_index])\n",
    "    hdf5_file.create_dataset('stft_phases', data=stft_phases[dev_test_index][dev_index])\n",
    "    hdf5_file.create_dataset('mel_spectrograms', data=mel_spectrograms[dev_test_index][dev_index])\n",
    "    hdf5_file.create_dataset('labels', data=labels[dev_test_index][dev_index])\n",
    "    hdf5_file.create_dataset('filenames', data=[filename.encode(\"ascii\", \"ignore\") for filename in segment_names[dev_test_index][dev_index]])\n",
    "    hdf5_file.create_dataset('durations', data=durations[dev_test_index][dev_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(config[\"output_folder\"], 'test_data.hdf5'), 'w') as hdf5_file:\n",
    "    hdf5_file.create_dataset('stft_magnitudes', data=stft_magnitudes[dev_test_index][test_index])\n",
    "    hdf5_file.create_dataset('stft_phases', data=stft_phases[dev_test_index][test_index])\n",
    "    hdf5_file.create_dataset('mel_spectrograms', data=mel_spectrograms[dev_test_index][test_index])\n",
    "    hdf5_file.create_dataset('labels', data=labels[dev_test_index][test_index])\n",
    "    hdf5_file.create_dataset('filenames', data=[filename.encode(\"ascii\", \"ignore\") for filename in segment_names[dev_test_index][test_index]])\n",
    "    hdf5_file.create_dataset('durations', data=durations[dev_test_index][test_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
